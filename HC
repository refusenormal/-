{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score\n",
    "import math\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-3-cd661e3481d0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-cd661e3481d0>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    data_path = 'C:\\Users\\32303\\Desktop\\baiduyunguangjia_cfg_A900527E-5BA6-4d22-8E96-E40D5C6EDF61.cfg'\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:\\Users\\32303\\Desktop\\baiduyunguangjia_cfg_A900527E-5BA6-4d22-8E96-E40D5C6EDF61.cfg'\n",
    "data= pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征描述统计分析及特征筛选\n",
    "\n",
    "## 去除缺失率高、类别较少以及字符型变量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDA_series(data):\n",
    "    '''\n",
    "    series的EDA函数\n",
    "    input:始数据\n",
    "    return:\n",
    "    result: series，原始数据EDA结果\n",
    "    '''\n",
    "    result = {}\n",
    "    result['count'] = len(data)\n",
    "    result['missing_count'] = data.isnull().sum()\n",
    "    result['missing_rate'] = result['missing_count'] / result['count']\n",
    "    result['count_unique'] = len(data.value_counts(normalize=True))\n",
    "    data.dropna(inplace=True)\n",
    "    if data.dtype=='object':\n",
    "        result['type'] = 'categorical'\n",
    "    else:\n",
    "        result['type'] = 'numeric'\n",
    "        result['max'] = data.max()\n",
    "        result['min'] = data.min()\n",
    "        result['mean'] = data.mean()\n",
    "        result['std'] = data.std() \n",
    "        zscore = (data-data.mean()) / data.std()\n",
    "        result['outlier_count'] = (zscore.abs()>6).sum()\n",
    "        result['outlier_rate'] = result['outlier_count'] / result['count']\n",
    "    if result['count_unique']<=2:\n",
    "        result['type'] = 'binary'\n",
    "    result = pd.Series(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDA_df(data):\n",
    "    '''\n",
    "    dataframe的EDA函数\n",
    "    input:\n",
    "    data: dataframe，原始数据\n",
    "    return:\n",
    "    result: dataframe，原始数据EDA结果，index为特征名\n",
    "    '''\n",
    "    result = []\n",
    "    for column in data.columns.tolist():\n",
    "        tmp = EDA_series(data[column])\n",
    "        tmp.name = column\n",
    "        result.append(tmp)\n",
    "    result = pd.concat(result,axis=1).T\n",
    "    columns_result = ['type','count','count_unique','max','min','mean','std','missing_count','missing_rate','outlier_count','outlier_rate']\n",
    "    result = result[columns_result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_stat = EDA_df(data)\n",
    "columns_drop = eda_stat[(eda_stat['missing_rate']>0.9)|(eda_stat['count_unique']<=1)|(eda_stat['type']=='categorical')].index\n",
    "data = data.drop(columns_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lr = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 等频分箱 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(data,columns_continous,quantiles):\n",
    "    '''\n",
    "    等频分bin函数\n",
    "    input:\n",
    "    data: dataframe，原始变量数据\n",
    "    columns_continous: list，连续型变量列表\n",
    "    quantiles: list，等频分bin的分位点列表\n",
    "    return:\n",
    "    data_bin: dataframe，分bin后的数据，每个bin为字符型\n",
    "    '''\n",
    "    data_bin = data.copy()\n",
    "    columns_cate = [column for column in data_bin.columns if column not in columns_continous]\n",
    "    for column in columns_continous:\n",
    "        X = data_bin[column].copy()\n",
    "        for i in range(len(quantiles)-1):\n",
    "            left = X.quantile(quantiles[i])\n",
    "            right = X.quantile(quantiles[i+1])\n",
    "            if i<len(quantiles)-2:\n",
    "                group = '['+str(left)+','+str(right)+')'\n",
    "                data_bin[column].iloc[np.where((X>=left)&(X<right))]=group\n",
    "            if i==len(quantiles)-2:\n",
    "                group = '['+str(left)+','+str(right)+']'\n",
    "                data_bin[column].iloc[np.where((X>=left)&(X<=right))]=group\n",
    "        data_bin[column].fillna('nan',inplace=True)\n",
    "    for column in columns_cate:\n",
    "        data_bin[column] = data_bin[column].astype(str)\n",
    "    return data_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = data_lr.columns[2:]\n",
    "Y_columns = 'TARGET'\n",
    "columns_continous = eda_stat[eda_stat['count_unique']>10].index.tolist()\n",
    "columns_continous = [column for column in columns_continous if column!='SK_ID_CURR']\n",
    "quantiles = [0.1*i for i in range(11)]\n",
    "data_bin = discretize(data_lr[X_columns],columns_continous,quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算IV，去除IV比较低的特征\n",
    "### IV<0.02说明单变量区分因变量能力较弱，可以筛选掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_iv_calc(data_bin,y):\n",
    "    '''\n",
    "    计算woe和iv函数\n",
    "    input:\n",
    "    data_bin: dataframe，分bin后的数据\n",
    "    y: series，目标变量，值为0或1\n",
    "    return:\n",
    "    data_woe: dataframe，woe映射后的数据\n",
    "    map_woe: dict，key为变量名，value为每个bin对应的woe值\n",
    "    map_iv: dict，key为变量名，value为iv值\n",
    "    '''\n",
    "    data_woe = data_bin.copy()\n",
    "    map_woe = {}\n",
    "    map_iv = {}\n",
    "    for column in data_woe.columns:\n",
    "        cross = pd.crosstab(data_woe[column],y)\n",
    "        cross[cross==0] = 1 #解决分母为0问题\n",
    "        cross = cross/cross.sum(axis=0)\n",
    "        woe = np.log(cross[0]/cross[1])\n",
    "        iv = ((cross[0]-cross[1])*np.log(cross[0]/cross[1])).sum()\n",
    "        map_woe[column] = dict(woe)\n",
    "        map_iv[column] = iv\n",
    "        data_woe[column] = data_woe[column].map(dict(woe))\n",
    "    return data_woe,map_woe,map_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_woe,map_woe,map_iv = woe_iv_calc(data_bin,data_lr[Y_columns])\n",
    "columns_imp = list({key for key,value in map_iv.items() if value>0.02})\n",
    "data_lr = data_lr[['SK_ID_CURR','TARGET']+columns_imp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除相关性较高的变量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_select = sorted(data_lr.columns[2:])\n",
    "data_cor = data_lr[columns_select].corr().abs()\n",
    "data_cor_lower = pd.DataFrame(np.tril(data_cor),index=data_cor.index,columns=data_cor.columns)\n",
    "\n",
    "columns_drop = []\n",
    "for column in data_cor_lower:\n",
    "    data_cor_select = pd.DataFrame(data_cor_lower.loc[(data_cor_lower[column]>0.8)&(data_cor_lower[column]<1),column])\n",
    "    if len(data_cor_select)>0:\n",
    "        data_cor_select = pd.DataFrame(data=data_cor_select.columns.tolist()+data_cor_select.index.tolist(),columns=['column_name'])\n",
    "        data_cor_select['IV'] = data_cor_select['column_name'].map(map_iv)\n",
    "        data_cor_select = data_cor_select.sort_values(by='IV',ascending=False)\n",
    "        columns_drop = columns_drop+data_cor_select['column_name'].tolist()[1:]  \n",
    "        \n",
    "columns_select = [column for column in columns_select if column not in columns_drop]\n",
    "data_lr = data_lr[['SK_ID_CURR','TARGET']+columns_select]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除多重共线性较高的变量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vif = data_lr.iloc[:,2:].copy()\n",
    "data_vif = sm.add_constant(data_vif) #使用 sm.add_constant () 在 array 上加入一列常项 1。\n",
    "data_vif = data_vif.replace([np.nan,np.inf],-9999)\n",
    "vif_select = pd.DataFrame(data=data_vif.columns,columns=['column_name'])\n",
    "vif_select['VIF'] = [variance_inflation_factor(data_vif.values,i) for i in range(data_vif.shape[1])]\n",
    "columns_select = vif_select.loc[vif_select['VIF']<10,'column_name'].tolist()\n",
    "columns_select = [column for column in columns_select if 'const' not in column]\n",
    "data_lr = data_lr[['SK_ID_CURR','TARGET']+columns_select]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保留WOE单调性较好的变量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_iv_select = {k:v for k,v in map_iv.items() if k in columns_select}\n",
    "map_iv_select_sorted = sorted(map_iv_select.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_woe_select = {k:v for k,v in map_woe.items() if k in columns_select}\n",
    "map_woe_select_sorted = {}\n",
    "for key in [k for k,v in map_woe_select.items()]:\n",
    "    data = pd.Series(map_woe_select[key])\n",
    "    data = data.reset_index()\n",
    "    data['left'] = -np.inf\n",
    "    if key in columns_continous:\n",
    "        data.loc[data['index']!='nan','left'] = data.loc[data['index']!='nan','index'].map(lambda X:float(X.split(',')[0].split('[')[1]))\n",
    "    else:\n",
    "        data.loc[data['index']!='nan','left'] = data.loc[data['index']!='nan','index'].map(lambda X:float(X))\n",
    "    data = data.sort_values(by='left')\n",
    "    data = data.drop('left',axis=1).set_index('index')\n",
    "    data.index.name=''\n",
    "    data.name=''\n",
    "    map_woe_select_sorted[key] = data.to_dict()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in [k for k,v in map_woe_select_sorted.items()]:\n",
    "    data = pd.Series(map_woe_select_sorted[key])\n",
    "    data = data.reset_index()\n",
    "    if key in columns_continous:\n",
    "        for index in data['index']:\n",
    "            if index!='nan':\n",
    "                left = round(float(index.split(',')[0].split('[')[1]),4)\n",
    "                if ')' in index:\n",
    "                    right = round(float(index.split(',')[1].split(')')[0]),4)\n",
    "                    data.loc[data['index']==index,'index'] = '['+str(left)+','+str(right)+')'\n",
    "                if ']' in index:\n",
    "                    right = round(float(index.split(',')[1].split(']')[0]),4)\n",
    "                    data.loc[data['index']==index,'index'] = '['+str(left)+','+str(right)+']'\n",
    "    data = data.set_index('index')    \n",
    "    data.index.name=''\n",
    "    data.name=''\n",
    "    map_woe_select_sorted[key] = data.to_dict()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_plot(map_woe,close=True,show_last=True):\n",
    "    '''\n",
    "    woe分布图\n",
    "    input:\n",
    "    map_woe: dict，key为变量名，value为每个bin对应的woe值，建议bin预先排序方便观察单调性\n",
    "    close: bool，是否打印woe分布图，默认True\n",
    "    show_last: bool，是否只保留最后一个变量的woe分布图，默认True\n",
    "    return:\n",
    "    result: dict，key为变量名，value为每个变量的woe分布图\n",
    "    '''\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus']=False\n",
    "    result={}\n",
    "    for i,feature in enumerate(map_woe):\n",
    "        data=pd.Series(map_woe[feature])\n",
    "        data.index.name=''\n",
    "        data.name=''\n",
    "        fig=plt.figure()\n",
    "        ax=fig.add_subplot(111)\n",
    "        data.plot(kind='bar',ax=ax)\n",
    "        ax.set_xlabel('变量分箱')\n",
    "        ax.set_ylabel('woe值')\n",
    "        ax.set_title('%s' %feature)\n",
    "        result[feature]=fig\n",
    "        if close and show_last and i<len(map_woe)-1:\n",
    "            plt.close('all')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_woe = woe_plot(map_woe_select_sorted)\n",
    "figs_woe[\"NAME_HOUSING_TYPE_House_apartment\"]=figs_woe.pop(\"NAME_HOUSING_TYPE_House / apartment\")\n",
    "figs_woe2={k:v for k,v in figs_woe.items()}\n",
    "for key in figs_woe2:\n",
    "    figs_woe[key].savefig('%s.png' %key,bbox_inches = 'tight')\n",
    "\n",
    "figs_woe['EXT_SOURCE_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_select = ['REGION_RATING_CLIENT_W_CITY','PREV_AMT_GOODS_PRICE_MIN','PREV_AMT_DOWN_PAYMENT_MAX',\n",
    "                  'INSTAL_PAYMENT_DIFF_MAX','INSTAL_AMT_PAYMENT_MIN','INSTAL_AMT_PAYMENT_MEAN','EXT_SOURCE_3',\n",
    "                  'EXT_SOURCE_2','EXT_SOURCE_1','DAYS_EMPLOYED','DAYS_BIRTH','BURO_AMT_CREDIT_SUM_DEBT_MEAN',\n",
    "                  'AMT_GOODS_PRICE','REGION_RATING_CLIENT_W_CITY','DAYS_REGISTRATION','DAYS_LAST_PHONE_CHANGE',\n",
    "                  'BURO_DAYS_CREDIT_VAR'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lr = data_lr[['SK_ID_CURR','TARGET']+columns_select]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练LR模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lr[columns_select] = data_woe[columns_select]\n",
    "X_columns = data_lr.columns[2:]\n",
    "Y_columns = 'TARGET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_lr[data_lr['TARGET']==0]))\n",
    "print(len(data_lr[data_lr['TARGET']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data_lr[X_columns],data_lr[Y_columns],test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'penalty':['l2'],'C':[0.001,0.01,0.1,1,10]}]\n",
    "clf = GridSearchCV(LogisticRegression(),tuned_parameters,cv=5,scoring='roc_auc')\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2',C=0.1)\n",
    "lr_clf = lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_calc(data,score_col,class_col):\n",
    "    '''\n",
    "    计算AUC值，并输出ROC曲线\n",
    "    input:\n",
    "    data: dataframe，包括预测prob和真实label\n",
    "    score_col: list，预测prob，一般为0-1之间的概率\n",
    "    class_col: list，真实label，一般为0或1\n",
    "    return:\n",
    "    auc_dict: dict，键值关系为{'auc': AUC值，'auc_fig': ROC曲线}\n",
    "    '''\n",
    "    auc_dict = {}\n",
    "    fpr,tpr,threshold = roc_curve((data[class_col[0]]).ravel(),data[score_col[0]].ravel())\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(fpr,tpr,color='b',label='ROC曲线下面积=%0.4f'%roc_auc,alpha=0.3)\n",
    "    plt.plot([0,1],[0,1],color='r',linestyle='--',alpha=0.3)\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.05])\n",
    "    plt.xlabel('假阳率')\n",
    "    plt.ylabel('真阳率')\n",
    "    plt.title('ROC曲线')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.close()\n",
    "    auc_dict['auc'] = roc_auc\n",
    "    auc_dict['auc_fig'] = fig\n",
    "    return auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_calc(data,score_col,class_col):\n",
    "    '''\n",
    "    计算KS值，并输出对应分割点和累计分布函数曲线图\n",
    "    input:\n",
    "    data: dataframe，包括预测prob和真实label\n",
    "    score_col: list，预测prob，一般为0-1之间的概率\n",
    "    class_col: list，真实label，一般为0或1\n",
    "    return:\n",
    "    ks_dict: dict，键值关系为{'ks': KS值，'split': KS值对应节点，'fig': 累计分布函数曲线图}\n",
    "    '''\n",
    "    ks_dict = {}\n",
    "    Bad = data.loc[data[class_col[0]]==1,score_col[0]]\n",
    "    Good = data.loc[data[class_col[0]]==0, score_col[0]]\n",
    "    ks,pvalue = stats.ks_2samp(Bad.values,Good.values)\n",
    "    crossfreq = pd.crosstab(data[score_col[0]],data[class_col[0]])\n",
    "    crossdens = crossfreq.cumsum(axis=0) / crossfreq.sum()\n",
    "    crossdens['gap'] = abs(crossdens[0] - crossdens[1])\n",
    "    score_split = crossdens[crossdens['gap'] == crossdens['gap'].max()].index[0]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    crossdens[[0]].plot(kind='line',ax=ax)\n",
    "    crossdens[[1]].plot(kind='line',style='--',ax=ax)\n",
    "    crossdens['gap'].plot(kind='line',style='g--',ax=ax)\n",
    "    ax.set_xlabel('模型分数')\n",
    "    ax.set_ylabel('累计占比')\n",
    "    ax.set_title('CDF曲线')\n",
    "    plt.close()\n",
    "    ks_dict['ks'] = ks\n",
    "    ks_dict['split'] = score_split\n",
    "    ks_dict['ks_fig'] = fig\n",
    "    return ks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_calc(actual,predict,bins=10):\n",
    "    '''\n",
    "    计算PSI值，并输出实际和预测占比分布曲线\n",
    "    input:\n",
    "    actual: series，实际值\n",
    "    predict: series，预测值\n",
    "    bins: int，等频分bin的个数\n",
    "    return:\n",
    "    psi_dict: dict，键值关系为{'psi': PSI值，'psi_fig': 实际和预期占比分布曲线}\n",
    "    '''\n",
    "    psi_dict = {}\n",
    "    psi_cut = []\n",
    "    actual_bins = []\n",
    "    predict_bins = []\n",
    "    actual_len = len(actual)\n",
    "    predict_len = len(predict)\n",
    "    if actual.isnull().any() == True:\n",
    "        bins = bins-1\n",
    "        actual_cnt = actual.isna().sum()\n",
    "        predict_cnt = predict.isna().sum()\n",
    "        actual_pct = (actual_cnt+0.0) / actual_len\n",
    "        predict_pct = (predict_cnt+0.0) / predict_len\n",
    "        psi = (predict_pct-actual_pct) * math.log((predict_pct+0.00000001)/actual_pct)\n",
    "        psi_cut.append(psi)\n",
    "        actual_bins.append(actual_pct)\n",
    "        predict_bins.append(predict_pct)\n",
    "    if len(actual)>0:\n",
    "        actual_values = actual.value_counts()\n",
    "        if (len(actual_values)<bins):\n",
    "            cuts = actual_values.index.values.tolist()\n",
    "        else:\n",
    "            out,bin_cut = pd.qcut(actual,bins,retbins=True,duplicates='drop')\n",
    "            cuts = bin_cut.tolist()[1:-1]\n",
    "        bins_after = len(cuts)+1\n",
    "        for i in range(1,(bins_after+1)):\n",
    "            if i==1:\n",
    "                lowercut = -np.inf\n",
    "                uppercut = cuts[i-1]\n",
    "            elif i==bins_after:\n",
    "                lowercut = cuts[i-2]\n",
    "                uppercut = np.inf\n",
    "            else:\n",
    "                lowercut = cuts[i-2]\n",
    "                uppercut = cuts[i-1]\n",
    "            actual_cnt = ((actual>=lowercut) & (actual<uppercut)).sum()+1\n",
    "            predict_cnt = ((predict>=lowercut) & (predict<uppercut)).sum()+1\n",
    "            actual_pct = (actual_cnt+0.0) / actual_len\n",
    "            predict_pct = (predict_cnt+0.0) / predict_len\n",
    "            psi = (predict_pct-actual_pct) * math.log((predict_pct+0.00000001)/actual_pct)\n",
    "            psi_cut.append(psi)\n",
    "            actual_bins.append(actual_pct)\n",
    "            predict_bins.append(predict_pct)\n",
    "    psi = sum(psi_cut)\n",
    "    nbins = len(actual_bins)\n",
    "    xlab = np.arange(1, nbins+1)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(xlab, np.array(actual_bins),'r',label='actual')\n",
    "    plt.plot(xlab, np.array(predict_bins),'b',label='predict')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('PSI曲线')\n",
    "    plt.close()\n",
    "    psi_dict['psi'] = psi\n",
    "    psi_dict['psi_fig'] = fig\n",
    "    return psi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_lr.loc[X_train.index,:]\n",
    "data_test = data_lr.loc[X_test.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['prob'] = lr_clf.predict_proba(X_train)[:,1]\n",
    "auc_dict = auc_calc(data_train,['prob'],['TARGET'])\n",
    "ks_dict = ks_calc(data_train,['prob'],['TARGET'])\n",
    "auc_value = auc_dict['auc']\n",
    "ks_value = ks_dict['ks']\n",
    "print('train auc: %f\\ntrain ks: %f' %(auc_value,ks_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_dict['auc_fig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_dict['ks_fig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['prob'] = lr_clf.predict_proba(X_test)[:,1]\n",
    "auc_dict = auc_calc(data_test,['prob'],['TARGET'])\n",
    "ks_dict = ks_calc(data_test,['prob'],['TARGET'])\n",
    "psi_dict = psi_calc(data_train['prob'],data_test['prob'])\n",
    "auc_value = auc_dict['auc']\n",
    "ks_value = ks_dict['ks']\n",
    "psi_value = psi_dict['psi']\n",
    "print('test auc: %f\\ntest ks: %f\\ntest psi: %f' %(auc_value,ks_value,psi_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_dict['auc_fig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_dict['ks_fig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_dict['psi_fig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
